# 2018-03-24 对延迟和吞吐量的测试

## 1 实验目的

这次实验的对象是同一台机器上的两个kernel：Linux-4.9.84 与 Linux-4.9.84-rt62。即一个mainline的kernel。以及它打上RT patch后的kernel，两者在编译前的配置中，只有Preemption Model不同，其它配置均相同。

机器配置：
* CPU：4核8线程
* Architecture：x86_64
* 内存：16G
* 操作系统：Ubuntu-16.04.4

这次实验希望测试在普通kernel与RT-kernel中，延迟和吞吐量的数据。

## 2 实验方案

### 2.1 实验变量

#### （1）延迟

程序开始后，需要多长的时间能返回结果，这个时间包括：

* 代码所需的计算时间
* 调度时间
* 其它程序占用CPU时，本程序阻塞等待的时间

我们所计算的程序延迟包括后两点，其中主要的是最后一点。

#### （2）吞吐量

系统的吞吐量表现为单位时间内，可以完成多少任务。我们用完成若干次任务所需要的时间来计算吞吐量：

```
    吞吐量 = 任务数 ／ 所需时间
```

### 2.2 实验程序

实验由两个程序组成，`test_throughput.c`用来测试吞吐量，`test_latency.c`用来测试延迟：

#### （1）test_throughput.c

程序由4个函数构成：

* `double calc()`

    包含了一段复杂的双精度浮点数计算，一次计算大约需要5秒多，这个时间是可调的，由`LOOP_COUNT`宏控制。这个函数主要用来消耗CPU，让CPU跑满。
    
* `void *thread_func(void *data)`

    这是每个线程的入口程序，会循环计算若干次`calc()`函数，次数可调，由`WORK_COUNT`宏控制。

* `int work()`

    这个函数用来生成若干个线程，线程数可调，由`THREAD_NUM`宏控制，这里取8（因为这台机器的cpu是4核8线程的）。生成所有的线程之后，会阻塞，等待所有线程join，全部线程join后，才返回main函数。

* `int main(int argc, char *argv[])`

    主函数，用来调用`work()`函数，以及使用`gettimeofday()`计时。

#### （2）test_latency.c

* `double calc()`

    同test_throughput.c中的`double calc()`。

* `void *thread_func(void *data)`

    同test_throughput.c中的`void *thread_func(void *data)`。

* `int non_rt_work()`

    这个函数用来生成若干个线程，线程数可调，由`THREAD_NUM`宏控制，这里取8（因为这台机器的cpu是4核8线程的）。生成所有的线程之后，会阻塞，等待所有线程join，全部线程join后，才返回main函数。
    
* `int rt_work()`

    和`int non_rt_work()`功能一样，只是多了设置线程属性的步骤。在函数开头，会设置生成的线程的属性，使生成的线程是高优先级的，可以抢占其它线程。

* `int main(int argc, char *argv[])`

    根据用户输入判断用`int non_rt_work()`还是`int rt_work()`，并计时。
    用户输入`test_latency -n`时，调用`int non_rt_work()`；输入`test_latency -r`时，调用`int rt_work()`。
    
**注意**：`test_latency.c`中修改了调度策略等，可能需要root权限运行。
    
### 2.3 实验过程记录

在我们的设置中，`test_throughput`单独执行需要约58秒。

![test_throughput_single_result](http://oy60g0sqx.bkt.clouddn.com/2018-03-24-test_throughput_single_result.png)

`test_latency -n`或`test_latency -r`单独执行需要约12秒。

![test_latency_single_result](http://oy60g0sqx.bkt.clouddn.com/2018-03-24-test_latency_single_result.png)

也就是说，两个程序串行之行的话，需要大约70秒。下面我们来测试它们并行执行的情况。

实验中打开了三个shell，上面的shell运行htop，用于观察cpu的分配情况，下面左边的shell运行`test_throughput`，下面右边的shell运行`test_latency`

#### （1）实验一：测试非RT环境下，系统的吞吐量和程序的延迟

在机器上打开两个终端，一个终端先执行`test_throughput`，紧接着在另一个终端执行`test_latency -n`。相当于在`test_throughput`的执行过程中插入了一段`test_latency -n`。

![test_double_running](http://oy60g0sqx.bkt.clouddn.com/2018-03-24-test_double_running.png)

可以看到，`test_latency -n`和`test_throughput`各有8个工作线程（以及1个阻塞的主控制线程），它们各自的8个线程均匀分布在8个cpu上，每个cpu上有一个`test_latency`的工作线程和一个`test_throughput`的工作线程，各占50%的cpu时间。

![test_double_result](http://oy60g0sqx.bkt.clouddn.com/2018-03-24-test_double_result.png)

可以看到，最后的运行结果，`test_latency -n`运行的时间加倍，因为它全程都只占用了50%的cpu在运行。`test_throughput`的运行时间增加了约12秒，因为它有约24秒的时间是运行在50%的cpu占用率下的。

#### （2）实验二：测试RT环境下，系统的吞吐量和程序的延迟

在机器上打开两个终端，一个终端先执行`test_throughput`，紧接着在另一个终端执行`test_latency -r`。相当于在`test_throughput`的执行过程中插入了一段`test_latency -r`。

![test_double_rt_1](http://oy60g0sqx.bkt.clouddn.com/2018-03-24-test_double_rt_1.png)

可以看到，`test_latency -r`和`test_throughput`各有8个工作线程（以及1个阻塞的主控制线程），它们各自的8个线程均匀分布在8个cpu上，每个cpu上有一个`test_latency`的工作线程和一个`test_throughput`的工作线程，其中，`test_latency`大约占95%的cpu时间，`test_throughput`大约占5%的cpu时间。

![test_double_rt_3](http://oy60g0sqx.bkt.clouddn.com/2018-03-24-test_double_rt_3.png)

可以看出，`test_latency -r`运行时间和它单独运行时几乎相同，因为它全程是在95%的cpu占用率下运行的。`test_throughput`的运行时间增加了约12秒，因为它有约12秒的时间基本上是挂起的。

## 3 实验结果

实验对比发现，在RT环境和非RT环境的对比中，RT环境下，程序的延迟有明显的降低，能比较接近程序单独执行时的延迟。但是，两种环境下系统的吞吐量基本没有变化。

### 3.1 原因分析   

Cpu是分时复用的，RT的程序有更高的优先级，占用更多的时间片，从而达到低延迟的效果。但是总体来说，并没有增加或者减少调度的量，所以全部程序运行完成所需的时间不变，也就是说，吞吐量不变。


